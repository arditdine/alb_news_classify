Çdo ditë, në internet futen miliarda foto që përmbajnë fytyra njerëzish. Ekspertët thonë se algoritme të sofistikuara mund t’i mbledhin këto imazhe, t’i krahasojnë dhe t’i përpunojnë. Nga kjo mund të përfitojnë agjencitë e zbatimit të ligjit, por edhe hakerët që synojnë vjedhjen dhe keqpërdorimin e të dhënave. Një kompani izraelite mendon se ekziston një mënyrë për ta parandaluar këtë keqpërdorim.Teknologjia e njohjes së fytyrës është duke marrë hov, që nga çelja e telefonit, tek gjetja e miqve në Facebook, dhe deri tek kalimi i kontrollit të pasaportave dhe kërkimi i personave të dyshuar.Kamerat e gjendura kudo marrin pamje të fytyrave tona dhe i kalojnë në internet, ku algoritme të ndryshme i krahasojnë me të dhëna të tjera. Kjo na ekspozon ndaj rrezikut të manipulimit. Në dallim nga fjalëkalimet, fytyra nuk mund të ndryshohet.“Nëpërmjet fytyrës mund të zbulohet informacion sensitiv për çdo person”, thotë Gil Perry, i kompanisë “D-ID”.Zoti Perry thotë se kompania e tij ka krijuar një algoritëm që mund të bllokojë përdorimin e fotove nga inteligjenca artificiale.“Mund t’ia bëjmë të pamundur ose tepër të vështirë inteligjencës artificiale njohjen e pamjeve të fytyrës, duke ruajtur ndërkohë shëmbëlltyrën njerëzore në imazh”, thotë zoti Perry.Në sytë tanë, pamjet e përpunuara duken njësoj, por algoritmet e njohjes së fytyrave tashmë nuk munden t’i shfrytëzojnë më për të identifikuar personin.Megjithatë, kjo lloj mbrojtjeje nuk do të mundet të përdoret nga të gjithë.“Disavantazhi është se nuk mund t’i detyrosh të gjithë njerëzit të publikojnë pamje vetëm pasi t’i kenë përpunuar me këtë teknologji”, thotë Yuval Elovici, i Universitetit Ben Gurion.Kompania “D-ID” po punon për të ofruar një zgjidhje që do të parandalojë përdorimin jozyrtar të teknologjisë së njohjes së fytyrave, ndërsa do t’u lejojë agjensive të zbatimit të ligjit që të vazhdojnë identifikimin e të dyshuarve. Ndërkohë, ekspertët thonë se është ende e nevojshme të vazhdojmë të përdorim fjalëkalime dhe t’i ndryshojmë ato rregullisht. /VoATweetData:22 Prill 2018 20:57				Autori:GazetaExpress 				